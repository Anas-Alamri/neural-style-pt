{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "style_paths = ['examples/inputs/starry_night.jpg','examples/inputs/cubist.jpg']\n",
    "style_seg_paths = None\n",
    "style_blend_weights = None\n",
    "content_path = 'examples/inputs/monalisa.jpg'\n",
    "content_seg_paths = ['examples/segments/monalisa1a.png','examples/segments/monalisa1b.png']\n",
    "image_size = 128\n",
    "content_weight = 5e0\n",
    "style_weight = 1e2\n",
    "tv_weight = 1e-3\n",
    "num_iterations = 100\n",
    "init = 'random'\n",
    "init_path = None\n",
    "output_path = 'out.png'\n",
    "original_colors = 0\n",
    "style_scale = 1.0\n",
    "print_iter = 100\n",
    "save_iter = 20\n",
    "\n",
    "\n",
    "# setup\n",
    "params = StylenetArgs()\n",
    "params.gpu = '0'\n",
    "params.backend = 'cudnn'\n",
    "\n",
    "\n",
    "dtype, multidevice, backward_device = setup_gpu(params)\n",
    "stylenet = StyleNet(params, dtype, multidevice, backward_device)\n",
    "\n",
    "\n",
    "# load content image\n",
    "content_image = preprocess(content_path, image_size).type(dtype)\n",
    "\n",
    "\n",
    "# load style images\n",
    "style_paths = get_style_image_paths(style_paths)\n",
    "num_styles = len(style_paths)\n",
    "style_size = int(image_size * style_scale)\n",
    "style_images = [preprocess(image, style_size).type(dtype)\n",
    "                for image in style_paths]\n",
    "\n",
    "# load init image\n",
    "init_image = None\n",
    "if init != 'random':\n",
    "    image_size = (content_image.size(2), content_image.size(3))\n",
    "    init_image = preprocess(init_path, image_size).type(dtype)\n",
    "\n",
    "# load content segmentation images\n",
    "content_masks = []\n",
    "if content_seg_paths != None:\n",
    "    content_masks = [preprocess(image, image_size, to_normalize=False).type(dtype)[0][0] \n",
    "                     for image in content_seg_paths]\n",
    "    \n",
    "# load style segmentation images\n",
    "if style_seg_paths != None:  \n",
    "    style_seg_images = [preprocess(image, image_size, to_normalize=False).type(dtype) \n",
    "                        for image in style_seg_paths]\n",
    "else:\n",
    "    style_seg_images = [torch.ones(style_images[i].shape).type(dtype)\n",
    "                        for i in range(num_styles)]\n",
    "style_masks = []\n",
    "for i in range(num_styles):\n",
    "    tmp_table = []\n",
    "    for j in range(num_styles):\n",
    "        style_seg_image = style_seg_images[i][0][0]\n",
    "        if i == j:\n",
    "            style_mask_i_j = style_seg_image.type(dtype)\n",
    "        else:                \n",
    "            style_mask_i_j = torch.zeros(style_seg_image.shape).type(dtype)\n",
    "        tmp_table.append(style_mask_i_j)\n",
    "    style_masks.append(tmp_table)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Handle style blending weights for multiple style inputs\n",
    "if style_blend_weights == None:  # needs len assert\n",
    "    style_blend_weights = [1.0 for image in style_paths]\n",
    "    style_blend_weights = [w / sum(style_blend_weights) for w in style_blend_weights]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stylenet.setup_masks(content_masks, style_masks)\n",
    "stylenet.capture_content(content_image)\n",
    "stylenet.capture_style(style_images, style_blend_weights)\n",
    "#stylenet.normalize_weights()\n",
    "\n",
    "\n",
    "def rand_image(w, h, c=3):\n",
    "    img0 = torch.randn(c, h, w).mul(0.001).unsqueeze(0).type(dtype)\n",
    "    return img0\n",
    "\n",
    "\n",
    "# Initialize the image\n",
    "if init == 'random':\n",
    "    B, C, H, W = content_image.size()\n",
    "    img = rand_image(H, W)\n",
    "\n",
    "elif init == 'image':\n",
    "    if init_image != None:\n",
    "        img = init_image.clone()\n",
    "    else:\n",
    "        img = content_image.clone()\n",
    "\n",
    "        \n",
    "img = nn.Parameter(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def iterate():\n",
    "    t[0] += 1\n",
    "    optimizer.zero_grad()\n",
    "    stylenet(img)\n",
    "    loss = stylenet.get_loss()\n",
    "    loss.backward()\n",
    "    maybe_print(stylenet, t[0], print_iter, num_iterations, loss)\n",
    "    maybe_save(img, t[0], save_iter, num_iterations, original_colors, output_path)\n",
    "    return loss\n",
    "\n",
    "\n",
    "optimizer, loopVal = setup_optimizer(img, params, num_iterations)\n",
    "t = [0]\n",
    "while t[0] <= loopVal:\n",
    "    optimizer.step(iterate)\n",
    "\n",
    "        \n",
    "print(\"go!\")\n",
    "        \n",
    "        \n",
    "\n",
    "content_seg_paths = ['examples/segments/monalisa1b.png','examples/segments/monalisa1a.png']\n",
    "if content_seg_paths != None:\n",
    "    content_masks = [preprocess(image, image_size, to_normalize=False).type(dtype)[0][0] \n",
    "                     for image in content_seg_paths]\n",
    "\n",
    "stylenet.setup_masks(content_masks, style_masks)\n",
    "stylenet.capture_content(content_image)\n",
    "stylenet.capture_style(style_images, style_blend_weights)\n",
    "#stylenet.set_to_loss_mode()\n",
    "\n",
    "optimizer, loopVal = setup_optimizer(img, params, num_iterations)\n",
    "t = [0]\n",
    "output_path = 'out2.png'\n",
    "print(\"go2!\")\n",
    "\n",
    "\n",
    "\n",
    "stylenet.set_content_weight(0)\n",
    "stylenet.set_style_weight(0)\n",
    "stylenet.set_tv_weight(0)\n",
    "\n",
    "\n",
    "while t[0] <= loopVal:\n",
    "    optimizer.step(iterate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
