{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 Architecture Detected\n",
      "Successfully loaded models/vgg19-d01eb7cb.pth\n",
      "conv1_1: 64 3 3 3\n",
      "conv1_2: 64 64 3 3\n",
      "conv2_1: 128 64 3 3\n",
      "conv2_2: 128 128 3 3\n",
      "conv3_1: 256 128 3 3\n",
      "conv3_2: 256 256 3 3\n",
      "conv3_3: 256 256 3 3\n",
      "conv3_4: 256 256 3 3\n",
      "conv4_1: 512 256 3 3\n",
      "conv4_2: 512 512 3 3\n",
      "conv4_3: 512 512 3 3\n",
      "conv4_4: 512 512 3 3\n",
      "conv5_1: 512 512 3 3\n",
      "conv5_2: 512 512 3 3\n",
      "conv5_3: 512 512 3 3\n",
      "conv5_4: 512 512 3 3\n",
      "Setting up style layer 2: relu1_1\n",
      "Setting up style layer 7: relu2_1\n",
      "Setting up style layer 12: relu3_1\n",
      "Setting up style layer 21: relu4_1\n",
      "Setting up content layer 23: relu4_2\n",
      "Setting up style layer 30: relu5_1\n",
      "Sequential(\n",
      "  (0): TVLoss()\n",
      "  (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaskedStyleLoss(\n",
      "    (crit): MSELoss()\n",
      "  )\n",
      "  (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaskedStyleLoss(\n",
      "    (crit): MSELoss()\n",
      "  )\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU(inplace=True)\n",
      "  (15): MaskedStyleLoss(\n",
      "    (crit): MSELoss()\n",
      "  )\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): ReLU(inplace=True)\n",
      "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): ReLU(inplace=True)\n",
      "  (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (23): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace=True)\n",
      "  (25): MaskedStyleLoss(\n",
      "    (crit): MSELoss()\n",
      "  )\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): ContentLoss(\n",
      "    (crit): MSELoss()\n",
      "  )\n",
      "  (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (30): ReLU(inplace=True)\n",
      "  (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (32): ReLU(inplace=True)\n",
      "  (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace=True)\n",
      "  (36): MaskedStyleLoss(\n",
      "    (crit): MSELoss()\n",
      "  )\n",
      ")\n",
      "Capturing content targets\n",
      "Capturing style target 1\n",
      "Capturing style target 2\n",
      "Running optimization with L-BFGS\n",
      "Iteration 100 / 500\n",
      "  Content 1 loss: 831246.8125\n",
      "  Style 1 loss: 2700.8642578125\n",
      "  Style 2 loss: 34061.25\n",
      "  Style 3 loss: 24595.162109375\n",
      "  Style 4 loss: 168334.28125\n",
      "  Style 5 loss: 761.9108276367188\n",
      "  Total loss: 1072567.75\n",
      "Iteration 200 / 500\n",
      "  Content 1 loss: 675415.625\n",
      "  Style 1 loss: 1174.1795654296875\n",
      "  Style 2 loss: 14083.818359375\n",
      "  Style 3 loss: 12214.884765625\n",
      "  Style 4 loss: 127166.8046875\n",
      "  Style 5 loss: 783.83642578125\n",
      "  Total loss: 841578.1875\n",
      "Iteration 300 / 500\n",
      "  Content 1 loss: 616847.375\n",
      "  Style 1 loss: 697.2779541015625\n",
      "  Style 2 loss: 8424.7158203125\n",
      "  Style 3 loss: 8941.275390625\n",
      "  Style 4 loss: 120551.625\n",
      "  Style 5 loss: 812.36279296875\n",
      "  Total loss: 766882.6875\n",
      "Iteration 400 / 500\n",
      "  Content 1 loss: 588086.625\n",
      "  Style 1 loss: 518.9166870117188\n",
      "  Style 2 loss: 6050.3193359375\n",
      "  Style 3 loss: 7716.2568359375\n",
      "  Style 4 loss: 119518.28125\n",
      "  Style 5 loss: 828.9395751953125\n",
      "  Total loss: 733112.5625\n",
      "Iteration 500 / 500\n",
      "  Content 1 loss: 572256.0625\n",
      "  Style 1 loss: 475.0867614746094\n",
      "  Style 2 loss: 4930.01318359375\n",
      "  Style 3 loss: 7092.470703125\n",
      "  Style 4 loss: 119434.3828125\n",
      "  Style 5 loss: 836.82470703125\n",
      "  Total loss: 715147.4375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def random_image(h, w, c=3):\n",
    "    image = torch.randn(c, h, w).mul(0.001).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "def random_image_like(base_image):\n",
    "    _, C, H, W = base_image.size()\n",
    "    return random_image(H, W, C)\n",
    "\n",
    "\n",
    "def optimize(stylenet, img, num_iterations, output_path, original_colors, print_iter, save_iter):\n",
    "    def iterate():\n",
    "        t[0] += 1\n",
    "        optimizer.zero_grad()\n",
    "        stylenet(img)\n",
    "        loss = stylenet.get_loss()\n",
    "        loss.backward()\n",
    "        maybe_print(stylenet, t[0], print_iter, num_iterations, loss)\n",
    "        maybe_save(img, t[0], save_iter, num_iterations, original_colors, output_path)\n",
    "        return loss\n",
    "    img = nn.Parameter(img)\n",
    "    optimizer, loopVal = setup_optimizer(img, stylenet.params, num_iterations)\n",
    "    t = [0]\n",
    "    while t[0] <= loopVal:\n",
    "        optimizer.step(iterate)\n",
    "\n",
    "def load_image(path, image_size, to_normalize=True):\n",
    "    image = preprocess(path, image_size, to_normalize)\n",
    "    return image\n",
    "\n",
    "        \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "style_paths = ['examples/inputs/starry_night.jpg','examples/inputs/cubist.jpg']\n",
    "style_seg_paths = None\n",
    "style_blend_weights = None\n",
    "content_path = 'examples/inputs/monalisa.jpg'\n",
    "content_seg_paths = ['examples/segments/monalisa1a.png','examples/segments/monalisa1b.png']\n",
    "#content_seg_paths = ['examples/segments/monalisa1b.png','examples/segments/monalisa1a.png']\n",
    "image_size = 512\n",
    "content_weight = 5e0\n",
    "style_weight = 1e2\n",
    "tv_weight = 1e-3\n",
    "num_iterations = 500\n",
    "init = 'random'\n",
    "init_path = None\n",
    "output_path = 'out1z.png'\n",
    "original_colors = 0\n",
    "style_scale = 1.0\n",
    "print_iter = 100\n",
    "save_iter = 100\n",
    "\n",
    "\n",
    "# setup\n",
    "params = StylenetArgs()\n",
    "params.gpu = '0'\n",
    "params.backend = 'cudnn'\n",
    "\n",
    "dtype, multidevice, backward_device = setup_gpu(params)\n",
    "stylenet = StyleNet(params, dtype, multidevice, backward_device)\n",
    "\n",
    "# load content image\n",
    "content_image = load_image(content_path, image_size).type(dtype)\n",
    "\n",
    "# load style images\n",
    "style_paths = get_style_image_paths(style_paths)\n",
    "style_size = int(image_size * style_scale)\n",
    "style_images = [load_image(path, style_size).type(dtype) for path in style_paths]\n",
    "#style_images = style_images[0]\n",
    "content_masks = [load_image(path, image_size, to_normalize=False).type(dtype)[0][0] for path in content_seg_paths]\n",
    "\n",
    "stylenet.capture(content_image, style_images, None, content_masks)#, None, content_masks, style_masks)\n",
    "#stylenet.capture(content_image, style_images, style_blend_weights, content_masks, style_masks)\n",
    "            \n",
    "#img = load_image(init_path, (content_image.size(2), content_image.size(3)), dtype)\n",
    "img = random_image_like(content_image).type(stylenet.dtype)\n",
    "optimize(stylenet, img, num_iterations, output_path, original_colors, print_iter, save_iter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
